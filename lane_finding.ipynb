{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n",
    "## First, I'll compute the camera calibration using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "%matplotlib inline\n",
    "\n",
    "camera_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class CameraModel():\n",
    "    def __init__(self, calibration_images):\n",
    "\n",
    "        mtx, dist = self._calibrate_camera(calibration_images)\n",
    "        self._camera_matrix = mtx\n",
    "        self._distortion = dist\n",
    "        \n",
    "    def undistort(self, image):\n",
    "        return cv2.undistort(image, self._camera_matrix, self._distortion, None, self._camera_matrix)\n",
    "        \n",
    "    def _calibrate_camera(self, calibration_images):\n",
    "        objpoints = [] # 3d points in real world space\n",
    "        imgpoints = [] # 2d points in image plane\n",
    "\n",
    "        nx = 9 # num corners on the x axis\n",
    "        ny = 6 # num corners on the y axis\n",
    "\n",
    "        # Prepare object points: (0,0,0), (1,0,0), (2,0,0) ... (8,5,0)\n",
    "        objp = np.zeros((ny * nx, 3), np.float32)\n",
    "        objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1, 2) # gen x,y coordinates\n",
    "\n",
    "        for file in calibration_images:\n",
    "            img = mpimg.imread(file)\n",
    "\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "            ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "\n",
    "            if ret:\n",
    "                imgpoints.append(corners)\n",
    "                objpoints.append(objp)\n",
    "            else:\n",
    "                print(\"Failed to find corners in\", file)\n",
    "\n",
    "        # Now use calibrate camera to get the intrinsics (and ignore extrinsics)\n",
    "        ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "        return mtx, dist\n",
    "\n",
    "cal_images = glob.glob('./camera_cal/calibration*.jpg')\n",
    "\n",
    "if camera_model is None:\n",
    "    camera_model = CameraModel(cal_images)    \n",
    "\n",
    "# Now test the distortion\n",
    "test_image = mpimg.imread('./camera_cal/calibration1.jpg')\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.tight_layout()\n",
    "ax1.imshow(test_image)\n",
    "ax1.set_title('Original Image')\n",
    "ax2.imshow(camera_model.undistort(test_image))\n",
    "ax1.set_title('Undistorted Image')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "assert(camera_model is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Thresholded Binary Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Edit this function to create your own pipeline.\n",
    "def pipeline1(img, s_thresh=(170, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(l_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "    # Stack each channel\n",
    "    # Note color_binary[:, :, 0] is all 0s, effectively an all black image. It might\n",
    "    # be beneficial to replace this channel with something else.\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary))\n",
    "    return color_binary\n",
    "\n",
    "image = mpimg.imread('./test_images/test1.jpg')\n",
    "\n",
    "result = pipeline1(transform_perspective(camera_model.undistort(image))\n",
    ")\n",
    "\n",
    "# Plot the result\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "\n",
    "ax1.imshow(image)\n",
    "ax1.set_title('Original Image', fontsize=40)\n",
    "\n",
    "ax2.imshow(result)\n",
    "ax2.set_title('Pipeline Result', fontsize=40)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient='x', sobel_kernel=3, thresh=(0, 255)):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    x = 1 if orient == 'x' else 0\n",
    "    y = 1 if orient == 'y' else 0\n",
    "    sobel = cv2.Sobel(gray, cv2.CV_64F, x, y, ksize=sobel_kernel)\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def mag_thresh(image, sobel_kernel=3, mag_thresh=(0, 255)):\n",
    "    \"\"\"\n",
    "    Calculate gradient magnitude\n",
    "\n",
    "    The magnitude, or absolute value, of the gradient is just the square root of\n",
    "    the squares of the individual x and y gradients. For a gradient in both the\n",
    "    x and y directions, the magnitude is the square root of the sum of the\n",
    "    squares.\n",
    "    \"\"\"\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # 3) Calculate the magnitude \n",
    "    mag = np.sqrt(np.power(sobelx, 2) + np.power(sobely, 2))\n",
    "    # 4) Scale to 8-bit (0 - 255) and convert to type = np.uint8\n",
    "    scaled_sobel = np.uint8(255*mag/np.max(mag))\n",
    "    # 5) Create a binary mask where mag thresholds are met\n",
    "    binary_output = np.zeros_like(scaled_sobel)\n",
    "    binary_output[(scaled_sobel >= mag_thresh[0]) & (scaled_sobel <= mag_thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def dir_threshold(image, sobel_kernel=3, thresh=(0, np.pi/2)):\n",
    "    # Calculate gradient direction\n",
    "    # Apply threshold\n",
    "\n",
    "    # 1) Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # 2) Take the gradient in x and y separately\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    abs_sobelx = np.absolute(sobelx)\n",
    "    abs_sobely = np.absolute(sobely)\n",
    "\n",
    "    # 4) Use np.arctan2(abs_sobely, abs_sobelx) to calculate the direction of the gradient \n",
    "    gradient_dir = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    \n",
    "    # 5) Create a binary mask where direction thresholds are met\n",
    "    binary_output = np.zeros_like(gradient_dir)\n",
    "    binary_output[(gradient_dir >= thresh[0]) & (gradient_dir <= thresh[1])] = 1\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    return binary_output\n",
    "\n",
    "def hls_select(img, thresh=(0, 255)):\n",
    "    # 1) Convert to HLS color space\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    S = hls[:,:,2]\n",
    "    # 2) Apply a threshold to the S channel\n",
    "    binary_output = np.zeros_like(S)\n",
    "    binary_output[(S > thresh[0]) & (S <= thresh[1])] = 1\n",
    "    # 3) Return a binary image of threshold result\n",
    "    return binary_output\n",
    "\n",
    "def pipeline(img, s_thresh=(180, 255), sx_thresh=(20, 100)):\n",
    "    img = np.copy(img)\n",
    "    # Convert to HSV color space and separate the V channel\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    h_channel = hsv[:,:,0]\n",
    "    l_channel = hsv[:,:,1]\n",
    "    s_channel = hsv[:,:,2]\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sx_thresh[0]) & (scaled_sobel <= sx_thresh[1])] = 1\n",
    "    \n",
    "    dir_binary = dir_threshold(img, sobel_kernel=5, thresh=(0.7, 1.3))\n",
    "\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    binary =  np.zeros_like(s_channel)\n",
    "    binary[((dir_binary == 1) & (sxbinary == 1)) | (s_binary == 1)] = 1\n",
    "\n",
    "    mag_binary = mag_thresh(img, sobel_kernel=3, mag_thresh=(150, 255))\n",
    "    binary2 =  np.zeros_like(s_channel)\n",
    "    binary2[(((dir_binary == 1)) & (mag_binary == 1) | (s_binary == 1))] = 1\n",
    "    \n",
    "    binary3 =  np.zeros_like(s_channel)\n",
    "    binary3[((sxbinary == 1)) | (s_binary == 1)] = 1\n",
    "    \n",
    "    return binary, binary2, binary3\n",
    "\n",
    "def combine_thresholds(image):\n",
    "    # Apply each of the thresholding functions\n",
    "    ksize=3\n",
    "    gradx = abs_sobel_thresh(image, orient='x', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    '''\n",
    "    grady = abs_sobel_thresh(image, orient='y', sobel_kernel=ksize, thresh=(20, 100))\n",
    "    mag_binary = mag_thresh(image, sobel_kernel=ksize, mag_thresh=(100, 200))\n",
    "    dir_binary = dir_threshold(image, sobel_kernel=ksize, thresh=(0.7, 1.3))\n",
    "    '''\n",
    "    hls_binary = hls_select(image, thresh=(90, 255))\n",
    "    combined = np.zeros_like(gradx)\n",
    "    #combined[((gradx == 1) & (grady == 1)) | ((mag_binary == 1) & (dir_binary == 1))] = 1\n",
    "    combined[(gradx == 1) | (hls_binary == 1)] = 1\n",
    "    return combined\n",
    "\n",
    "test_image = mpimg.imread('./test_images/test1.jpg')\n",
    "#combined = combine_thresholds(test_image)\n",
    "combined, combined2, combined3 = pipeline(test_image)\n",
    "# Plot the result\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_image)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(combined, cmap='gray')\n",
    "ax2.set_title('Combined Thresholds', fontsize=50)\n",
    "ax3.imshow(combined2, cmap='gray')\n",
    "ax3.set_title('Combined Thresholds', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "ax4.imshow(combined3, cmap='gray')\n",
    "ax4.set_title('Combined Thresholds', fontsize=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_perspective_transform_func():\n",
    "    # src and dst points found externally\n",
    "    src = np.float32([[581, 460], [702, 460], [1017, 665], [285, 665]])\n",
    "    dst = np.float32([[250, 0], [1046, 0], [1046, 708], [250, 708]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    def apply_perspective_transform(img):\n",
    "        height, width = img.shape[:2]\n",
    "        return cv2.warpPerspective(img, M, (width, height), flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return apply_perspective_transform\n",
    "\n",
    "transform_perspective = get_perspective_transform_func()\n",
    "\n",
    "test_image1 = mpimg.imread('./test_images/straight_lines1.jpg')\n",
    "\n",
    "top_down1 = transform_perspective(camera_model.undistort(test_image1))\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(test_image1)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(top_down1)\n",
    "ax2.set_title('Undistorted and warped', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "test_image2 = mpimg.imread('./test_images/straight_lines2.jpg')\n",
    "top_down2 = transform_perspective(camera_model.undistort(test_image2))\n",
    "ax3.imshow(test_image2)\n",
    "ax3.set_title('Original Image', fontsize=50)\n",
    "ax4.imshow(top_down2)\n",
    "ax4.set_title('Undistorted and warped', fontsize=50)\n",
    "plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
